{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHR1JqHOMRT1"
      },
      "source": [
        "# CS4320 - Introduction to Machine Learning\n",
        "\n",
        "## Homework 4: Logistic regression, hyperparameter optimization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n25HDcpWdrOQ"
      },
      "source": [
        "Please type your name and A number here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "krzQ3U35dmxB"
      },
      "outputs": [],
      "source": [
        "Name = \"Joshua McClung\"\n",
        "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'\n",
        "\n",
        "A_number = \"A02256312\"\n",
        "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTW89q0sMRT2"
      },
      "source": [
        "## Imports "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lliyIwrEMRT2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 16\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    cross_val_score,\n",
        "    cross_validate,\n",
        "    train_test_split,\n",
        ")\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nTc4JYaMRT3"
      },
      "source": [
        "## Exercise 1: implementing `DummyClassifier`\n",
        "<hr>\n",
        "rubric={points:25}\n",
        "\n",
        "You will implement the simplest possible classifier, `DummyClassifier`.\n",
        "\n",
        "As a reminder, `DummyClassifier` is meant as a baseline and is generally the worst possible \"model\" you could \"fit\" to a dataset. All it does is predict the most popular class in the training set. So if there are more label(0) than label(1) it predicts label(0) every time, and if there are more label(1) than label(0) it predicts label(1) every time. For `predict_proba` it looks at the frequencies in the training set, so if you have 30% label(0) 70% label(1) it predicts `[0.3 0.7]` every time. Thus, `fit` only looks at `y` (not `X`).\n",
        "\n",
        "Below you will find starter code for a class called `MyDummyClassifier`, which has methods `fit()`, `predict()`, `predict_proba()` and `score()`. Your task is to fill in those four functions. To get you started, I have given you a `return` statement in each case that returns the correct data type: `fit` can return nothing, `predict` returns an array whose size is the number of examples, `predict_proba` returns an array whose size is the number of examples x 2, and `score` returns a number.\n",
        "\n",
        "The next code block has some tests you can use to assess whether your code is working. \n",
        "\n",
        "I suggest starting with `fit` and `predict`, and making sure those are working before moving on to `predict_proba`. For `predict_proba`, you should return the frequency of each class in the training data, which is the behaviour of [`DummyClassifier(strategy='prior')`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html?highlight=dummyclassifier+strategy+prior). Your `score` function should call your `predict` function. Again, you can compare with `DummyClassifier` using the code below.\n",
        "\n",
        "To simplify this question, you can assume **binary classification**, and furthermore that these classes are **encoded as 0 and 1**. In other words, you can assume that `y` contains only 0s and 1s. The real `DummyClassifier` works when you have more than two classes, and also works if the target values are encoded differently, for example as \"cat\", \"dog\", \"mouse\", etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0hqSNY5sMRT4"
      },
      "outputs": [],
      "source": [
        "class MyDummyClassifier:\n",
        "    \"\"\"\n",
        "    A baseline classifier that predicts the most common class.\n",
        "    The predicted probabilities come from the relative frequencies\n",
        "    of the classes in the training data.\n",
        "\n",
        "    This implementation only works when y only contains 0s and 1s.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.probabilities = {}\n",
        "\n",
        "\n",
        "    def fit(self, X:np.ndarray, y:np.ndarray):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        total = y.shape[0]\n",
        "        for value, count in zip(values, counts):\n",
        "            self.probabilities[value] = count/total\n",
        "        return None \n",
        "\n",
        "    def predict(self, X):\n",
        "        max_probable = max(self.probabilities, key=lambda k: self.probabilities[k])\n",
        "        return np.full(X.shape[0],max_probable)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return np.array([list(x for x in self.probabilities.values()) for _ in range(X.shape[0])])\n",
        "\n",
        "    def score(self, X, y):\n",
        "        max_probable = max(self.probabilities, key=lambda k: self.probabilities[k])\n",
        "        return len([1 for x in y if x == max_probable])/len(y) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJq_q0qiMRT4"
      },
      "source": [
        "Below are some tests for `predict` using randomly generated data. You may want to run the cell a few times to make sure you explore the different cases (or automate this with a loop or random seeds)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7wvFcB5CMRT4"
      },
      "outputs": [],
      "source": [
        "# For testing, generate random data\n",
        "n_train = 101\n",
        "n_valid = 21\n",
        "d = 5\n",
        "X_train_dummy = np.random.randn(n_train, d)\n",
        "X_valid_dummy = np.random.randn(n_valid, d)\n",
        "y_train_dummy = np.random.randint(2, size=n_train)\n",
        "y_valid_dummy = np.random.randint(2, size=n_valid)\n",
        "\n",
        "my_dc = MyDummyClassifier()\n",
        "sk_dc = DummyClassifier(strategy=\"prior\")\n",
        "\n",
        "my_dc.fit(X_train_dummy, y_train_dummy)\n",
        "sk_dc.fit(X_train_dummy, y_train_dummy)\n",
        "\n",
        "assert np.array_equal(my_dc.predict(X_train_dummy), sk_dc.predict(X_train_dummy))\n",
        "assert np.array_equal(my_dc.predict(X_valid_dummy), sk_dc.predict(X_valid_dummy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AvhG5n5MRT5"
      },
      "source": [
        "Below are some tests for `predict_proba`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v-05HEiIMRT5"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(\n",
        "    my_dc.predict_proba(X_train_dummy), sk_dc.predict_proba(X_train_dummy)\n",
        ")\n",
        "assert np.allclose(\n",
        "    my_dc.predict_proba(X_valid_dummy), sk_dc.predict_proba(X_valid_dummy)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpQIVhQ3MRT5"
      },
      "source": [
        "Below are some tests for `score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k9LvzdYKMRT5"
      },
      "outputs": [],
      "source": [
        "assert np.isclose(\n",
        "    my_dc.score(X_train_dummy, y_train_dummy), sk_dc.score(X_train_dummy, y_train_dummy)\n",
        ")\n",
        "assert np.isclose(\n",
        "    my_dc.score(X_valid_dummy, y_valid_dummy), sk_dc.score(X_valid_dummy, y_valid_dummy)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5KkCpMWMRT5",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-8e3cc53df86a7e14",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "toc-hr-collapsed": true
      },
      "source": [
        "## Exercise 2: Trump Tweets\n",
        "<hr>\n",
        "rubric={points:35}\n",
        "\n",
        "For the rest of this assignment we'll be looking at a [dataset of Donald Trump's tweets](https://www.kaggle.com/austinreese/trump-tweets) as of June 2020. You should start by downloading the dataset. Unzip it and move the file `realdonaldtrump.csv` into this directory. As usual, please do not submit the dataset when you submit the assignment. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9pyaIYSsMRT5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1698308935</th>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
              "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
              "      <td>2009-05-04 13:54:25</td>\n",
              "      <td>510</td>\n",
              "      <td>917</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701461182</th>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
              "      <td>Donald Trump will be appearing on The View tom...</td>\n",
              "      <td>2009-05-04 20:00:10</td>\n",
              "      <td>34</td>\n",
              "      <td>267</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737479987</th>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
              "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
              "      <td>2009-05-08 08:38:08</td>\n",
              "      <td>13</td>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1741160716</th>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
              "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
              "      <td>2009-05-08 15:40:15</td>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1773561338</th>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
              "      <td>\"My persona will never be that of a wallflower...</td>\n",
              "      <td>2009-05-12 09:07:28</td>\n",
              "      <td>1375</td>\n",
              "      <td>1945</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         link  \\\n",
              "id                                                              \n",
              "1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
              "1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
              "1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
              "1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
              "1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
              "\n",
              "                                                      content  \\\n",
              "id                                                              \n",
              "1698308935  Be sure to tune in and watch Donald Trump on L...   \n",
              "1701461182  Donald Trump will be appearing on The View tom...   \n",
              "1737479987  Donald Trump reads Top Ten Financial Tips on L...   \n",
              "1741160716  New Blog Post: Celebrity Apprentice Finale and...   \n",
              "1773561338  \"My persona will never be that of a wallflower...   \n",
              "\n",
              "                           date  retweets  favorites mentions hashtags  \n",
              "id                                                                      \n",
              "1698308935  2009-05-04 13:54:25       510        917      NaN      NaN  \n",
              "1701461182  2009-05-04 20:00:10        34        267      NaN      NaN  \n",
              "1737479987  2009-05-08 08:38:08        13         19      NaN      NaN  \n",
              "1741160716  2009-05-08 15:40:15        11         26      NaN      NaN  \n",
              "1773561338  2009-05-12 09:07:28      1375       1945      NaN      NaN  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df = pd.read_csv(\"realdonaldtrump.csv\", index_col=0)\n",
        "tweets_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rdzMVX8oMRT5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43352, 7)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M80K1rN5MRT6"
      },
      "source": [
        "We will be trying to predict whether a tweet will go \"viral\", defined as having more than 10,000 retweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9kPboX_cMRT6"
      },
      "outputs": [],
      "source": [
        "y = tweets_df[\"retweets\"] > 10_000 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ak2bYYFMRT6"
      },
      "source": [
        "To make predictions, we'll be using only the content (text) of the tweet. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nsut7RqaMRT6"
      },
      "outputs": [],
      "source": [
        "X = tweets_df[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHDv4GSFMRT6"
      },
      "source": [
        "For the purpose of this assignment, you can ignore all the other columns in the original dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAPtqdzcMRT6"
      },
      "source": [
        "#### 2(a) ordering the steps\n",
        "rubric={points:8}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43afb-2VMRT6"
      },
      "source": [
        "Let's start by building a model using `CountVectorizer` and `LogisticRegression`. The code required to do this has been provided below, but in the wrong order. \n",
        "\n",
        "- Rearrange the lines of code to correctly fit the model and compute the cross-validation score. {points: 4} \n",
        "- Add a short comment to each block to describe what the code is doing. {points: 4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkWw3qsCMRT7",
        "tags": [
          "raises-exception"
        ]
      },
      "outputs": [],
      "source": [
        "# '''You can skip this cell and insert your code in the next cell. After that, to make sure you can run all cells without any error, you can comment the code in this cell or simply delete this cell'''\n",
        "# # YOUR COMMENT HERE\n",
        "# countvec = CountVectorizer(stop_words=\"english\")\n",
        "\n",
        "# # YOUR COMMENT HERE\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=321)\n",
        "\n",
        "# # YOUR COMMENT HERE\n",
        "# cross_val_results = pd.DataFrame(\n",
        "#     cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
        "# )\n",
        "\n",
        "# # YOUR COMMENT HERE\n",
        "# pipe = make_pipeline(countvec, lr)\n",
        "\n",
        "# # YOUR COMMENT HERE\n",
        "# cross_val_results.mean()\n",
        "\n",
        "# # YOUR COMMENT HERE\n",
        "# lr = LogisticRegression(max_iter=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "O6B4WPzIMRT7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fit_time       2.429125\n",
              "score_time     0.171517\n",
              "test_score     0.897890\n",
              "train_score    0.967045\n",
              "dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Rearrange the code above and add your comment for each line'''\n",
        "# Split Train/Test Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=321)\n",
        "\n",
        "# Initialize Count Vectorizer preprocessor\n",
        "countvec = CountVectorizer(stop_words=\"english\")\n",
        "\n",
        "# Create Logistic Regression Model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Make Pipeline with count vectorizer and logistic regression\n",
        "pipe = make_pipeline(countvec, lr)\n",
        "\n",
        "# Do Cross Validation\n",
        "cross_val_results = pd.DataFrame(\n",
        "    cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
        ")\n",
        "\n",
        "# Return mean score\n",
        "cross_val_results.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imnr-RgCcrCP"
      },
      "source": [
        "Expected Output. (Note that we round to three decimal places. Your output could have more decimal places. )\n",
        "- test_score     0.897\n",
        "- train_score    0.967"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EFl-NTiMRT7"
      },
      "source": [
        "#### 2(b) Cross-validation fold sub-scores\n",
        "rubric={points:3}\n",
        "\n",
        "Above we averaged the scores from the 5 folds of cross-validation. \n",
        "\n",
        "- Print out the 5 individual scores. Reminder: `sklearn` calls them `\"test_score\"` but they are really (cross-)validation scores. {points:1} \n",
        "- Are the 5 scores close to each other or spread far apart? (This is a bit subjective, answer to the best of your ability.) {points:1}\n",
        "- How does the size of this dataset (number of rows) compare to the cities dataset we have been using in class? How does this relate to the different sub-scores from the 5 folds? {points:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HXTVaHDnscHP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   fit_time  score_time  test_score  train_score\n",
            "0  2.522705    0.189525    0.899123     0.966014\n",
            "1  2.185933    0.179614    0.899739     0.968859\n",
            "2  2.362374    0.166608    0.896356     0.965976\n",
            "3  2.215698    0.161609    0.898201     0.968552\n",
            "4  2.858915    0.160230    0.896032     0.965823\n"
          ]
        }
      ],
      "source": [
        "'''Insert your code here'''\n",
        "print(cross_val_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCBVlDhVQ24g"
      },
      "source": [
        "Type your answer:\n",
        "\n",
        "- Like you said before it is hard to say for certain, but overall the scores are pretty close, the ranges are less than 1/3 of a percent\n",
        "- This dataset has much more rows than the cities dataset.\n",
        "    - This would explain why our cross validation scores are so similar. This is because even accounting for a reduction in training data, we still have a significant amount of points on which to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRWX4knvMRT7"
      },
      "source": [
        "#### 2(c) baseline\n",
        "rubric={points:5}\n",
        "\n",
        "By the way, are these scores any good? \n",
        "\n",
        "- Run `DummyClassifier` (or `MyDummyClassifier`!) on this dataset (You only do cross validation on the training data like (a)). {points:2}\n",
        "    - Expected Output. Mean cross_val_results is\n",
        "        - test_score     0.738\n",
        "        - train_score    0.738\n",
        "- Compare the `DummyClassifier` score to what you got from logistic regression above. Does logistic regression seem to be doing anything useful? {points:1}\n",
        "- Is it necessary to use `CountVectorizer` here? Briefly explain. {points:2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "H4DxMIdOyJS_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "fit_time       0.004817\n",
              "score_time     0.001743\n",
              "test_score     0.738543\n",
              "train_score    0.738543\n",
              "dtype: float64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dc = DummyClassifier()\n",
        "cross_val_results = pd.DataFrame(\n",
        "    cross_validate(dc, X_train, y_train, return_train_score=True)\n",
        ")\n",
        "\n",
        "# Return mean score\n",
        "cross_val_results.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIABdTQC0fiv"
      },
      "source": [
        "Type your answer: So it looks like our logistic regression model is at least doing something. As the dummy classifier only gets ~74% accuracy. We do not need to use the count vectorizer for the dummy classifier because this classifier doesn't care what the input (X) is at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baOChYrAMRT7",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ba1f8ea22638cf75",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### 2(d) probability scores\n",
        "rubric={points:5}\n",
        "\n",
        "Here we train a logistic regression classifier on the entire training set: \n",
        "\n",
        "(Note: this is relying on the `pipe` variable from 2(a) - you'll need to redefine it if you overwrote that variable in between.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IOa6AmwKMRT7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer(stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;logisticregression&#x27;, LogisticRegression(max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('countvectorizer', CountVectorizer(stop_words='english')),\n",
              "                ('logisticregression', LogisticRegression(max_iter=1000))])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe.fit(X_train, y_train) # train a logistic regression classifier on the entire training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EWRNUspMRT8"
      },
      "source": [
        "Using this model, find the tweet in the **test set** with the highest predicted probability of being viral. Print out the tweet and the associated probability score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "jNsuQ2yZ8nHN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max score: 0.9999999956099612\n",
            "There was No Collusion with Russia (except by the Democrats). When will this very expensive Witch Hunt Hoax ever end? So bad for our Country. Is the Special Counsel/Justice Department leaking my lawyers letters to the Fake News Media? Should be looking at Dems corruption instead?\n"
          ]
        }
      ],
      "source": [
        "'''Insert your code here'''\n",
        "proba = pipe.predict_proba(X_train)\n",
        "tweet_with_score = pd.DataFrame({'tweet':X_train,pipe.classes_[0]:proba[:,0], pipe.classes_[1]:proba[:,1]})\n",
        "print('max score:',tweet_with_score[True].max())\n",
        "print(tweet_with_score[tweet_with_score[True] == tweet_with_score[True].max()]['tweet'].to_numpy()[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVtKG5SyMRT8",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f910e9d1d6d09182",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### 2(e) coefficients\n",
        "rubric={points:4}\n",
        "\n",
        "We can extract the `CountVectorizer` and `LogisticRegression` objects from the `make_pipeline` object as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "m0eUc7DcMRT8"
      },
      "outputs": [],
      "source": [
        "vec_from_pipe = pipe.named_steps[\"countvectorizer\"]\n",
        "lr_from_pipe = pipe.named_steps[\"logisticregression\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pXuZLNEMRT8"
      },
      "source": [
        "Using these extracted components above, display the 5 words with the highest coefficients and the 5 words with the smallest coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Y7JABALKNg-P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highest words\n",
            "              word    weight\n",
            "36825  transcripts  2.380695\n",
            "10915  coronavirus  2.434496\n",
            "14919         fake  2.692571\n",
            "24999         mini  2.712601\n",
            "17729   harassment  2.732361\n",
            "Lowest words\n",
            "                  word    weight\n",
            "30315  realdonaldtrump -3.116874\n",
            "37055     trump2016pic -2.637181\n",
            "6928       barackobama -2.564993\n",
            "37051        trump2016 -2.315430\n",
            "2219              1pic -2.294937\n"
          ]
        }
      ],
      "source": [
        "'''Insert your code here'''\n",
        "weights = pd.DataFrame({'word':list(vec_from_pipe.get_feature_names_out()) ,'weight':lr_from_pipe.coef_[0]})\n",
        "weights = weights.sort_values(by='weight')\n",
        "print(\"Highest words\")\n",
        "print(weights.tail(5))\n",
        "print(\"Lowest words\")\n",
        "print(weights.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gxrFtMleF8e"
      },
      "source": [
        "- The highest 5 words should be: harassment, mini, fake, coronavirus, transcripts.\n",
        "- The lowest 5 words should be: 1pic, trump2016, barackobama, trump2016pic, realdonaldtrump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bst-ityMRT8"
      },
      "source": [
        "#### 2(f)\n",
        "rubric={points:10}\n",
        "\n",
        "scikit-learn provides a lot of useful tools like `make_pipeline` and `cross_validate`, which are awesome. But with these fancy tools it's also easy to lose track of what is actually happening under the hood. Here, your task is to \"manually\" (without `Pipeline`) compute logistic regression's validation score(that is, train on 80% and validate on 20%) of the training data.\n",
        "\n",
        "You should start with the following `CountVectorizer` and `LogisticRegression` objects. You only need to furtherly split `X_train` and `y_train` into 80% training set and 20% validation set. Use lr.score() to show your validation score of your model performing on validation set.(In order to grade, we set random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "O5a_LFr9MRT8"
      },
      "outputs": [],
      "source": [
        "countvec = CountVectorizer(stop_words=\"english\")\n",
        "lr = LogisticRegression(max_iter=1000)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "GmZN1rTYg6k3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8929724742426572"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Insert your code here'''\n",
        "# Split into train/valid\n",
        "vX_train, X_valid, vy_train, y_valid = train_test_split(X_train, y_train, train_size=0.8, test_size=0.2, random_state=123)\n",
        "\n",
        "# Transform Data\n",
        "countvec.fit(vX_train)\n",
        "vX_train = countvec.transform(vX_train)\n",
        "X_valid = countvec.transform(X_valid)\n",
        "\n",
        "# Fit LR\n",
        "lr.fit(vX_train, vy_train)\n",
        "\n",
        "# Score on validation Data\n",
        "lr.score(X_valid, y_valid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQF_HwR41ijP"
      },
      "source": [
        "Expected output value: 0.893"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDElLzibMRT8"
      },
      "source": [
        "Meta-comment:I think this type of question (and Exercise 1) is a useful middle ground. I do want you to know what is going on in `Pipeline` and in `cross_validate` even if we don't cover the details of `fit`. To get into logistic regression's `fit` requires a bunch of math; here, we're keeping it more conceptual and avoiding all those prerequisites."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj3qijcUMRT9",
        "toc-hr-collapsed": true
      },
      "source": [
        "## Exercise 3: hyperparameter optimization\n",
        "<hr>\n",
        "rubric={points:25}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLOeCebnMRT9",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-5e9e6fdea209d872",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### 3(a)\n",
        "rubric={points:4}\n",
        "\n",
        "The following code varies the `max_features` hyperparameter of `CountVectorizer` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `max_features`. It also prints the results. Based on the plot/output, what value of `max_features` seems best? Briefly explain.\n",
        "\n",
        "Note: the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZFGyo0zMRT9"
      },
      "outputs": [],
      "source": [
        "train_scores = []\n",
        "cv_scores = []\n",
        "\n",
        "max_features = [10, 100, 1000, 10_000, 100_000]\n",
        "\n",
        "for mf in max_features:\n",
        "    #     print(mf)\n",
        "    pipe = make_pipeline(\n",
        "        CountVectorizer(stop_words=\"english\", max_features=mf),\n",
        "        LogisticRegression(max_iter=1000),\n",
        "    )\n",
        "    cv_results = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
        "    train_scores.append(cv_results[\"train_score\"].mean())\n",
        "    cv_scores.append(cv_results[\"test_score\"].mean())\n",
        "\n",
        "plt.semilogx(max_features, train_scores, label=\"train\")\n",
        "plt.semilogx(max_features, cv_scores, label=\"valid\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"max_features\")\n",
        "plt.ylabel(\"accuracy\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7up_9-_CMRT9"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"max_features\": max_features, \"train\": train_scores, \"cv\": cv_scores})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnn4LOkX23x9"
      },
      "source": [
        "Type your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPQT5c7tMRT9"
      },
      "source": [
        "#### 3(b)\n",
        "rubric={points:4}\n",
        "\n",
        "The following code varies the `C` hyperparameter of `LogisticRegression` and makes a plot (with the x-axis on a log scale) that shows train/cross-validation scores vs. `C`. Based on the plot, what value of `C` seems best?\n",
        "\n",
        "Note: the code may take a minute or two to run. You can uncomment the `print` statement if you want to see it show the progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne67GMhmMRT9"
      },
      "outputs": [],
      "source": [
        "train_scores = []\n",
        "cv_scores = []\n",
        "\n",
        "C_vals = 10.0 ** np.arange(-1.5, 2, 0.5)\n",
        "\n",
        "for C in C_vals:\n",
        "    # print(C)\n",
        "    pipe = make_pipeline(\n",
        "        CountVectorizer(stop_words=\"english\", max_features=None),\n",
        "        LogisticRegression(max_iter=1000, C=C),\n",
        "    )\n",
        "    cv_results = cross_validate(pipe, X_train, y_train, return_train_score=True)\n",
        "\n",
        "    train_scores.append(cv_results[\"train_score\"].mean())\n",
        "    cv_scores.append(cv_results[\"test_score\"].mean())\n",
        "\n",
        "plt.semilogx(C_vals, train_scores, label=\"train\")\n",
        "plt.semilogx(C_vals, cv_scores, label=\"valid\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"C\")\n",
        "plt.ylabel(\"accuracy\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_R271j2MRT9"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"C\": C_vals, \"train\": train_scores, \"cv\": cv_scores})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dUggjmsMRT-"
      },
      "source": [
        "Type your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLwFSeUwMRT-"
      },
      "source": [
        "#### 3(c)\n",
        "rubric={points:12}\n",
        "\n",
        "- Using `GridSearchCV`, jointly optimize `max_features` and `C` across all the combinations of values we tried above.{points:8} \n",
        "  - Note: the code might be a bit slow here. \n",
        "  - Setting `n_jobs=-1` should speed it up if you have a multi-core processor.\n",
        "  - You can reduce the number of folds (e.g. `cv=2`) to speed it up if necessary.\n",
        "- What are the best values of `max_features` and `C` according to your grid search?(You can just print your best values){points:4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yHPfPOF3ePf"
      },
      "outputs": [],
      "source": [
        "'''Insert your code here'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEd0vuGO2KJ3"
      },
      "source": [
        "Please print out your best values of max_feature and C. They should be 100000 and 0.316 respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkr6jYFuMRT-"
      },
      "source": [
        "#### 3(d)\n",
        "rubric={points:5}\n",
        "\n",
        "- Evaluate your final model on the test set.{points:3} \n",
        "    - Expected test accuracy is 0.899\n",
        "- How does your test accuracy compare to your validation accuracy?{points:2} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GifXNTF5FDtT"
      },
      "outputs": [],
      "source": [
        "'''Insert your code here'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdtL5X-lH1mc"
      },
      "source": [
        "Type your answer here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBhrNBerMRT-"
      },
      "source": [
        "## Exercise 4: Very short answer questions\n",
        "rubric={points:15}\n",
        "\n",
        "Each question is worth 3 points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoyCJvjHMRT-"
      },
      "source": [
        "1. What is the problem with calling `fit_transform` on your test data with `CountVectorizer`? \n",
        "2. Why is it important to follow the Golden Rule? If you violate it, will that give you a worse classifier?\n",
        "3. If you could only access one of `predict` or `predict_proba`, which one would you choose? Briefly explain.\n",
        "4. What are two advantages of using sklearn `Pipeline`s? \n",
        "5. What are two advantages of `RandomizedSearchCV` over `GridSearchCV`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2LZ0eQEMRT-"
      },
      "source": [
        "Type your answer here:\n",
        "\n",
        "1. \n",
        "\n",
        "2. \n",
        "\n",
        "3. \n",
        "\n",
        "4. \n",
        "\n",
        "5. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmnHq1b6MRT_"
      },
      "source": [
        "## Submission instructions \n",
        "\n",
        "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
        "\n",
        "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
        "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
        "3. Please keep your notebook clean and delete any throwaway code."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "74864006475560d55db2f16790ed02bd14eca518a5bb693f0e32a0ca4b797964"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
